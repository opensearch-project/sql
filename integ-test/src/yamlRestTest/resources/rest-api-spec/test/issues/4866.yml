setup:
  - do:
      query.settings:
        body:
          transient:
            plugins.calcite.enabled: true
  - do:
      bulk:
        index: hdfs_logs
        refresh: true
        body:
          - '{ "index": { "_id": 1 } }'
          - '{ "date": "20081109", "time": "203615", "pid": 148, "level": "INFO", "component": "dfs.FSNamesystem", "content": "BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.31.85:50010 is added to blk_-7017553867379051457 size 67108864" }'
          - '{ "index": { "_id": 2 } }'
          - '{ "date": "20081109", "time": "204132", "pid": 26, "level": "INFO", "component": "dfs.FSNamesystem", "content": "BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.107.19:50010 is added to blk_-3249711809227781266 size 67108864" }'
          - '{ "index": { "_id": 3 } }'
          - '{ "date": "20081109", "time": "204925", "pid": 663, "level": "WARN", "component": "dfs.DataNode$PacketResponder", "content": "PacketResponder failed for blk_6996194389878584395" }'
          - '{ "index": { "_id": 4 } }'
          - '{ "date": "20081109", "time": "205035", "pid": 31, "level": "WARN", "component": "dfs.DataNode$PacketResponder", "content": "PacketResponder failed for blk_-1547954353065580372" }'


---
teardown:
  - do:
      query.settings:
        body:
          transient:
            plugins.calcite.enabled : false


---
"Patterns with specified max_sample_count should return correct result":
  - skip:
      features:
        - headers
        - allowed_warnings
  - do:
      allowed_warnings:
        - 'Loading the fielddata on the _id field is deprecated and will be removed in future versions. If you require sorting or aggregating on this field you should also include the id in the body of your documents, and map this field as a keyword field that has [doc_values] enabled'
      headers:
        Content-Type: 'application/json'
      ppl:
        body:
          query: 'source=hdfs_logs | patterns content method=brain mode=aggregation max_sample_count=2 variable_count_threshold=3'
  - match: { total: 2 }
  - match: { schema: [{"name": "patterns_field", "type": "string"}, {"name": "pattern_count", "type": "bigint"}, {"name": "sample_logs", "type": "array"}] }
  - length: { datarows: 2 }
  # Verify each pattern has exactly 2 sample logs (max_sample_count=2)
  - length: { datarows.0.2: 2 }
  - length: { datarows.1.2: 2 }

