/*
 * Copyright OpenSearch Contributors
 * SPDX-License-Identifier: Apache-2.0
 */

plugins {
    id 'java-library'
    id "io.freefair.lombok"
    id 'jacoco'
    id 'antlr'
    id 'com.diffplug.spotless' version '6.22.0'
    id 'com.github.johnrengelman.shadow'
}

// Apply common utilities from language-grammar
apply from: "${rootProject.projectDir}/language-grammar/build.gradle"

repositories {
    mavenCentral()
}

tasks.register('downloadG4Files', Exec) {
    description = 'Download remote .g4 files from GitHub'

    executable 'curl'

    def opensearchSparkBranch = "0.6"
    def apacheSparkVersionTag = "v3.5.1"
    args '-o', 'src/main/antlr/FlintSparkSqlExtensions.g4', "https://raw.githubusercontent.com/opensearch-project/opensearch-spark/${opensearchSparkBranch}/flint-spark-integration/src/main/antlr4/FlintSparkSqlExtensions.g4"
    args '-o', 'src/main/antlr/SparkSqlBase.g4', "https://raw.githubusercontent.com/opensearch-project/opensearch-spark/${opensearchSparkBranch}/flint-spark-integration/src/main/antlr4/SparkSqlBase.g4"
    args '-o', 'src/main/antlr/SqlBaseParser.g4', "https://raw.githubusercontent.com/apache/spark/${apacheSparkVersionTag}/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4"
    args '-o', 'src/main/antlr/SqlBaseLexer.g4', "https://raw.githubusercontent.com/apache/spark/${apacheSparkVersionTag}/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseLexer.g4"
    args '-o', 'src/main/antlr/OpenSearchPPLParser.g4', "https://raw.githubusercontent.com/opensearch-project/opensearch-spark/${opensearchSparkBranch}/ppl-spark-integration/src/main/antlr4/OpenSearchPPLParser.g4"
    args '-o', 'src/main/antlr/OpenSearchPPLLexer.g4', "https://raw.githubusercontent.com/opensearch-project/opensearch-spark/${opensearchSparkBranch}/ppl-spark-integration/src/main/antlr4/OpenSearchPPLLexer.g4"
}

generateGrammarSource {
    arguments += ['-visitor', '-package', 'org.opensearch.sql.spark.antlr.parser']
    source = sourceSets.main.antlr
    outputDirectory = file("build/generated-src/antlr/main/org/opensearch/sql/asyncquery/antlr/parser")
}
configurations {
    compile {
        extendsFrom = extendsFrom.findAll { it != configurations.antlr }
    }
}

dependencies {
    antlr "org.antlr:antlr4:4.7.1"

    implementation project(':core')
    implementation project(':spark') // TODO: dependency to spark should be eliminated
    implementation project(':datasources') // TODO: dependency to datasources should be eliminated
    implementation 'org.json:json:20231013'
    implementation 'com.google.code.gson:gson:2.8.9'

    testImplementation(platform("org.junit:junit-bom:5.9.3"))

    testCompileOnly('org.junit.jupiter:junit-jupiter')
    testImplementation 'org.mockito:mockito-core:5.7.0'
    testImplementation 'org.mockito:mockito-junit-jupiter:5.7.0'

    testCompileOnly('junit:junit:4.13.1') {
        exclude group: 'org.hamcrest', module: 'hamcrest-core'
    }
    testRuntimeOnly("org.junit.vintage:junit-vintage-engine") {
        exclude group: 'org.hamcrest', module: 'hamcrest-core'
    }
    testRuntimeOnly("org.junit.jupiter:junit-jupiter-engine") {
        exclude group: 'org.hamcrest', module: 'hamcrest-core'
    }
    testRuntimeOnly("org.junit.platform:junit-platform-launcher") {
        because 'allows tests to run from IDEs that bundle older version of launcher'
    }
}

spotless {
    java {
        target fileTree('.') {
            include '**/*.java'
            exclude '**/build/**', '**/build-*/**'
        }
        importOrder()
        removeUnusedImports()
        trimTrailingWhitespace()
        endWithNewline()
        googleJavaFormat('1.17.0').reflowLongStrings().groupArtifact('com.google.googlejavaformat:google-java-format')
    }
}

test {
    useJUnitPlatform()
    testLogging {
        events "skipped", "failed"
        exceptionFormat "full"
    }
}

jacocoTestReport {
    reports {
        html.required = true
        xml.required = true
    }
    afterEvaluate {
        classDirectories.setFrom(files(classDirectories.files.collect {
            fileTree(dir: it, exclude: ['**/antlr/parser/**'])
        }))
    }
}
test.finalizedBy(project.tasks.jacocoTestReport)
jacocoTestCoverageVerification {
    violationRules {
        rule {
            element = 'CLASS'
            //ã€€TODO: Add unit tests in async-query-core and remove exclusions
            excludes = [
                    'org.opensearch.sql.spark.asyncquery.model.*',
                    'org.opensearch.sql.spark.data.constants.*',
                    'org.opensearch.sql.spark.dispatcher.model.*',
                    'org.opensearch.sql.spark.dispatcher.*',
                    'org.opensearch.sql.spark.execution.session.*',
                    'org.opensearch.sql.spark.execution.statement.*',
                    'org.opensearch.sql.spark.flint.*',
                    'org.opensearch.sql.spark.flint.operation.*',
                    'org.opensearch.sql.spark.rest.*',
                    'org.opensearch.sql.spark.utils.SQLQueryUtils.*',
                    'org.opensearch.sql.spark.validator.SQLQueryValidationVisitor'
            ]
            limit {
                counter = 'LINE'
                minimum = 1.0
            }
            limit {
                counter = 'BRANCH'
                minimum = 1.0
            }
        }
    }
    afterEvaluate {
        classDirectories.setFrom(files(classDirectories.files.collect {
            fileTree(dir: it, exclude: ['**/antlr/parser/**'])
        }))
    }
}
check.dependsOn jacocoTestCoverageVerification

// Keep the existing shadowJar configuration
shadowJar {
    // Get version from root project or from system property
    def shadowVersion = rootProject.version

    archiveBaseName.set('async-query-core')
    archiveClassifier.set('all')

    // Use the version from parent project
    if (version != shadowVersion) {
        logger.lifecycle("Using root project version for shadowJar: ${shadowVersion}")
        archiveVersion.set(shadowVersion.toString())
    }

    from sourceSets.main.output
    configurations = [project.configurations.runtimeClasspath]
}

// Maven publishing configuration - using root project version
ext {
    // Define Maven artifact properties
    mavenArtifactId = 'async-query-core'
    mavenDirName = 'direct-query'
}

// Use parent project version for consistency
task prepareShadowJarForMaven(dependsOn: shadowJar) {
    description = 'Prepare shadow JAR for Maven publishing'
    group = 'Publishing'

    doLast {
        // Get consistent version
        def pubVersion = rootProject.version

        logger.lifecycle("Preparing async-query-core for Maven publication with version: ${pubVersion}")

        def mavenDir = utilities.prepareMavenDir(opensearchGroup, mavenDirName, pubVersion.toString())
        def shadowJarFile = shadowJar.archiveFile.get().asFile
        def targetJarName = "${mavenArtifactId}-${pubVersion}.jar"

        // Copy the JAR with Maven naming convention
        copy {
            from shadowJarFile
            into mavenDir
            rename { targetJarName }
        }

        // Create POM file
        utilities.createPom(mavenDir, opensearchGroup, mavenArtifactId, pubVersion.toString(),
                "OpenSearch Async Query Core Library")

        // Generate checksums
        utilities.generateChecksums(new File(mavenDir, targetJarName))
        utilities.generateChecksums(new File(mavenDir, "${mavenArtifactId}-${pubVersion}.pom"))

        logger.lifecycle("Async Query Core JAR prepared for publishing:")
        logger.lifecycle("  - Group ID: ${opensearchGroup}")
        logger.lifecycle("  - Artifact ID: ${mavenArtifactId}")
        logger.lifecycle("  - Version: ${pubVersion}")
        logger.lifecycle("  - Path: ${mavenDir}")
    }
}

// Main task to prepare async-query artifacts
task prepareAsyncQueryArtifacts {
    description = 'Prepare all async-query-core artifacts for Maven publishing'
    group = 'Publishing'
    dependsOn prepareShadowJarForMaven
}